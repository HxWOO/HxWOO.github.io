---
layout: post
title:  "ğŸš—ğŸ’¨ ìë™ì°¨ ì—°ë¹„ ì˜ˆì¸¡ DNN íšŒê·€ ëª¨ë¸ë§ ì‹¤ìŠµ"
date:   2025-09-04 10:00:00 +0900
categories: [WOORI_FISA, Deep_Learning]
tags: [PyTorch, DNN, Regression, Feature Engineering, Normalization, '#ìš°ë¦¬FISì•„ì¹´ë°ë¯¸', '#ìš°ë¦¬FISA', '#AIì—”ì§€ë‹ˆì–´ë§', '#K-ë””ì§€í„¸íŠ¸ë ˆì´ë‹', '#ìš°ë¦¬ì—í”„ì•„ì´ì—ìŠ¤', '#ê¸€ë¡œë²Œì†Œí”„íŠ¸ì›¨ì–´ìº í¼ìŠ¤']
---

<br>

## ğŸš— ì˜¤ëŠ˜ì˜ ëª©í‘œ: ìë™ì°¨ ì—°ë¹„ ì˜ˆì¸¡ ëª¨ë¸ ë§Œë“¤ê¸°

ì˜¤ëŠ˜ì€ 1970-80ë…„ëŒ€ì˜ í´ë˜ì‹í•œ ìë™ì°¨ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ì—°ë¹„(MPG)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” DNN íšŒê·€ ëª¨ë¸ì„ PyTorchë¡œ ë§Œë“¤ì–´ë³´ì•˜ë‹¤. ë°ì´í„° ì „ì²˜ë¦¬ë¶€í„° íŠ¹ì„± ê³µí•™, ëª¨ë¸ë§, ê·¸ë¦¬ê³  í‰ê°€ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ê²½í—˜í•´ë³´ëŠ” ì•Œì°¬ ì‹¤ìŠµì´ì—ˆë‹¤. ğŸ˜„

> ### âœ¨ í•µì‹¬ ì •ë¦¬
> **#ë°ì´í„°ì „ì²˜ë¦¬ #íŠ¹ì„±ê³µí•™ #ì •ê·œí™” #PyTorch #DNN #íšŒê·€ëª¨ë¸ #ê·œì œ**

---

### ğŸ› ï¸ í•œëˆˆì— ë³´ëŠ” ê³¼ì •

| ë‹¨ê³„ | ë‚´ìš© | í•µì‹¬ ê¸°ìˆ /ê°œë… |
| --- | --- | --- |
| **1. ë°ì´í„° ì¤€ë¹„** | UCI ì„œë²„ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ `pandas`ë¡œ í™•ì¸í–ˆë‹¤. | `pandas.read_csv` |
| **2. ì „ì²˜ë¦¬** | `Horsepower` ì—´ì˜ ê²°ì¸¡ì¹˜ë¥¼ ê¹”ë”í•˜ê²Œ ì œê±°í–ˆë‹¤. | `dropna()` |
| **3. íŠ¹ì„± ê³µí•™** | `Model Year`ëŠ” ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê³ , `Origin`ì€ ì›-í•« ì¸ì½”ë”©ì„ ì‹œë„í–ˆë‹¤. | `torch.bucketize`, `one_hot` |
| **4. ì •ê·œí™”** | `StandardScaler`ë¡œ ìˆ˜ì¹˜ ë°ì´í„°ë“¤ì˜ ìŠ¤ì¼€ì¼ì„ ë§ì·„ë‹¤. ì•ˆ í•˜ë©´ í•™ìŠµì´ ë¶ˆì•ˆì •í•´ì§„ë‹¤. | `StandardScaler` |
| **5. ëª¨ë¸ë§ ë° í•™ìŠµ** | PyTorchë¡œ ê°„ë‹¨í•œ DNN íšŒê·€ ëª¨ë¸ì„ ë§Œë“¤ê³  ì—´ì‹¬íˆ í•™ìŠµì‹œì¼°ë‹¤. ğŸ¤“ | `torch.nn.Sequential`, `MSELoss`, `SGD` |
| **6. ì„±ëŠ¥ í‰ê°€ ë° ê·œì œ** | í•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ MSEì™€ MAEë¡œ í‰ê°€í•˜ê³ , ê³¼ì í•©ì„ ë§‰ê¸° ìœ„í•œ L1/L2 ê·œì œë„ ì‚´í´ë³´ì•˜ë‹¤. | `L1Loss`, `weight_decay` |

---

### ğŸ“œ ì‚½ì§ˆê³¼ ë°°ì›€ì˜ ê¸°ë¡

#### 1. ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬

- **ë°ì´í„° ë¡œë“œ**: `pd.read_csv`ë¡œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ë‹¤. ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ íŒŒì¼ì´ë¼ `sep=" "` ì˜µì…˜ì„ ì¤¬ë‹¤.
- **ê²°ì¸¡ì¹˜ ì²˜ë¦¬**: `Horsepower` ì—´ì— `?`ê°€ ì„ì—¬ìˆì—ˆë‹¤. `na_values='?'`ë¡œ `NaN` ë³€í™˜ í›„ `dropna()`ë¡œ ë‚ ë ¤ë²„ë ¸ë‹¤. ì† ì‹œì›! ğŸ‘
- **ë°ì´í„° ë¶„í• **: `train_test_split`ìœ¼ë¡œ í›ˆë ¨ìš©ê³¼ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¥¼ ë‚˜ëˆ´ë‹¤. ê¸°ë³¸ ì¤‘ì˜ ê¸°ë³¸ì´ë‹¤.

```python
# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
import pandas as pd
import torch
from sklearn.model_selection import train_test_split

url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'
column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',
                'Acceleration', 'Model Year', 'Origin']
df = pd.read_csv(url, names=column_names, na_values="?", comment='\t', sep=" ", skipinitialspace=True)
df = df.dropna()

# ë°ì´í„° ë¶„í• 
X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(df.iloc[:, 1:], df['MPG'], test_size=0.2, random_state=121)
```

#### 2. ë°ì´í„° ì •ê·œí™” (Normalization)

> **ì •ê·œí™”ëŠ” ì„ íƒì´ ì•„ë‹Œ í•„ìˆ˜!** âœ¨
> íŠ¹ì„±ë§ˆë‹¤ ê°’ì˜ ë²”ìœ„ê°€ ë„ˆë¬´ ë‹¬ë¼ì„œ(`Weight` vs `Cylinders`) ì •ê·œí™”ëŠ” í•„ìˆ˜ì˜€ë‹¤. ì•ˆ ê·¸ëŸ¬ë©´ ëª¨ë¸ì´ í° ê°’ì—ë§Œ íœ˜ë‘˜ë¦´ ìˆ˜ ìˆë‹¤. `StandardScaler`ë¥¼ ì¨ì„œ ê°„ë‹¨íˆ í•´ê²°í–ˆë‹¤.

```python
from sklearn.preprocessing import StandardScaler

numeric_columns = ['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration']
scaler = StandardScaler()

# í›ˆë ¨ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ ë° ì ìš©
X_train_df[numeric_columns] = scaler.fit_transform(X_train_df[numeric_columns])
# í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” í•™ìŠµëœ ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ë³€í™˜ë§Œ!
X_test_df[numeric_columns] = scaler.transform(X_test_df[numeric_columns])
```

#### 3. íŠ¹ì„± ê³µí•™ (Feature Engineering)

- **`Model Year`**: ì—°ë„ë¥¼ ëª‡ ê°œ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì—ˆë‹¤ (`torch.bucketize`). ë„ˆë¬´ ë§ì€ ì—°ë„ë¥¼ ê·¸ëŒ€ë¡œ ì“°ê¸°ë³´ë‹¤ ê·¸ë£¹ìœ¼ë¡œ ë§Œë“œëŠ” ê²Œ ë‚«ë‹¤ê³  íŒë‹¨í–ˆë‹¤.
- **`Origin`**: ì œì¡° êµ­ê°€ë¥¼ ì›-í•« ì¸ì½”ë”©(`one_hot`)í–ˆë‹¤. ëª¨ë¸ì´ êµ­ê°€ë¥¼ ì„œì—´ë¡œ ì˜¤í•´í•˜ë©´ ì•ˆ ë˜ë‹ˆê¹Œ!

```python
from torch.nn.functional import one_hot

# Model Year ë²„í‚·í™”
boundaries = torch.tensor([73, 76, 79])
X_train_df['Model Year Bucketed'] = torch.bucketize(torch.tensor(X_train_df['Model Year'].values), boundaries, right=True)
X_test_df['Model Year Bucketed'] = torch.bucketize(torch.tensor(X_test_df['Model Year'].values), boundaries, right=True)

# Origin ì›-í•« ì¸ì½”ë”© ë° í…ì„œ ê²°í•©
train_origin_encoded = one_hot(torch.tensor(X_train_df['Origin'].values) % 3)
test_origin_encoded = one_hot(torch.tensor(X_test_df['Origin'].values) % 3)

x_train = torch.cat([torch.tensor(X_train_df[numeric_columns + ['Model Year Bucketed']].values), train_origin_encoded], 1).float()
x_test = torch.cat([torch.tensor(X_test_df[numeric_columns + ['Model Year Bucketed']].values), test_origin_encoded], 1).float()

y_train = torch.FloatTensor(y_train_df.values)
y_test = torch.FloatTensor(y_test_df.values)
```

#### 4. DNN ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ

- **ëª¨ë¸ ì„¤ê³„**: `torch.nn.Sequential`ë¡œ ê°„ë‹¨í•œ DNN ëª¨ë¸ì„ ë§Œë“¤ì—ˆë‹¤. ì€ë‹‰ì¸µ 2ê°œì— í™œì„±í™” í•¨ìˆ˜ëŠ” ReLU!
- **ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €**: íšŒê·€ ë¬¸ì œë¼ ì†ì‹¤ í•¨ìˆ˜ëŠ” `MSELoss`, ì˜µí‹°ë§ˆì´ì €ëŠ” í´ë˜ì‹í•œ `SGD`ë¥¼ ì¼ë‹¤.
- **í•™ìŠµ ì‹œì‘!**: `DataLoader`ë¡œ ë°ì´í„°ë¥¼ ì¡°ê¸ˆì”© ëª¨ë¸ì— ì£¼ë©´ì„œ 200 ì—í¬í¬ ë™ì•ˆ í•™ìŠµì‹œì¼°ë‹¤. ì†ì‹¤ì´ ì­‰ì­‰ ë–¨ì–´ì§€ëŠ” ê±¸ ë³´ë‹ˆ ë¿Œë“¯í–ˆë‹¤. ğŸ‰

```python
from torch.utils.data import DataLoader, TensorDataset
import torch.nn as nn

# ë°ì´í„° ë¡œë” ìƒì„±
train_ds = TensorDataset(x_train, y_train)
train_dl = DataLoader(train_ds, batch_size=8, shuffle=True)

# ëª¨ë¸ ì •ì˜
hidden_units = [8, 4]
input_size = x_train.shape[1]
all_layers = []
for hidden_unit in hidden_units:
    layer = nn.Linear(input_size, hidden_unit)
    all_layers.append(layer)
    all_layers.append(nn.ReLU())
    input_size = hidden_unit
all_layers.append(nn.Linear(hidden_units[-1], 1))
model = nn.Sequential(*all_layers)

# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
loss_fn = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001)

# ëª¨ë¸ í•™ìŠµ
torch.manual_seed(1)
num_epochs = 200
for epoch in range(num_epochs):
    loss_train = 0
    for X, y in train_dl:
        pred = model(X).squeeze()
        loss = loss_fn(pred, y)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        loss_train += loss.item()
    if epoch % 20 == 0:
        print(f'Epoch {epoch}, Loss {loss_train/len(train_dl):.4f}')
```

#### 5. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ê·œì œ

- **ì„±ëŠ¥ í‰ê°€**: í•™ìŠµì´ ëë‚œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€í–ˆë‹¤. MSEì™€ MAE ê°’ì„ í™•ì¸í•˜ë‹ˆ, ë‚˜ì˜ì§€ ì•Šì€ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤.
- **ê³¼ì í•© ë°©ì§€**: ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì—ë§Œ ë„ˆë¬´ ìµìˆ™í•´ì§€ëŠ” ê±¸ ë§‰ê¸° ìœ„í•´ **ê·œì œ(Regularization)**ë¼ëŠ” ê¸°ë²•ì´ ìˆë‹¤.
    - **L1 (Lasso)**: ë¶ˆí•„ìš”í•œ íŠ¹ì„±ì˜ ê°€ì¤‘ì¹˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ì–´ ë²„ë¦°ë‹¤.
    - **L2 (Ridge)**: ê°€ì¤‘ì¹˜ë“¤ì´ ë„ˆë¬´ ì»¤ì§€ì§€ ì•Šê²Œ ì „ë°˜ì ìœ¼ë¡œ ëˆ„ë¥´ëŠ” ëŠë‚Œ. `SGD` ì˜µí‹°ë§ˆì´ì €ì˜ `weight_decay`ë¡œ ì‰½ê²Œ ì ìš©í•  ìˆ˜ ìˆë‹¤.

```python
# ëª¨ë¸ í‰ê°€
model.eval()
with torch.no_grad():
    pred = model(x_test).squeeze()
    test_mse = loss_fn(pred, y_test)
    test_mae = nn.L1Loss()(pred, y_test)
    print(f'Test MSE: {test_mse.item():.4f}') # ê²°ê³¼ í™•ì¸!
    print(f'Test MAE: {test_mae.item():.4f}')

# L2 ê·œì œ ì ìš© ì˜ˆì‹œ
optimizer_l2 = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.5)
```

---

### âœ¨ ì˜¤ëŠ˜ì˜ íšŒê³ 

ë°ì´í„° ì „ì²˜ë¦¬ë¶€í„° ëª¨ë¸ë§, í‰ê°€ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ê²½í—˜í•´ë³¸ ì¢‹ì€ ì‹¤ìŠµì´ì—ˆë‹¤. íŠ¹íˆ **ë°ì´í„° ì •ê·œí™”**ì˜ ì¤‘ìš”ì„±ì„ ë‹¤ì‹œ í•œë²ˆ ëŠê¼ˆë‹¤. PyTorchë¡œ ì§ì ‘ ëª¨ë¸ì„ ì§œë³´ë‹ˆ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ êµ¬ì¡°ê°€ ë” ëª…í™•í•˜ê²Œ ì´í•´ëê³ , í›ˆë ¨ ì†ì‹¤ê³¼ í…ŒìŠ¤íŠ¸ ì†ì‹¤ì„ ë¹„êµí•˜ë©° ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ê°€ëŠ í•´ë³¼ ìˆ˜ ìˆì—ˆê³ , **ê·œì œ**ì˜ í•„ìš”ì„±ë„ ì²´ê°í–ˆë‹¤.

ë‹¤ìŒì—ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ì„ ë” ëŒì–´ì˜¬ë ¤ ë´ì•¼ê² ë‹¤. 
