---
layout: post
title:  "내 손으로 만드는 AI 비서! Elasticsearch와 로컬 LLM으로 RAG 시스템 구축하기 🧠"
date:   2025-08-18 11:00:00 +0900
categories: [AI Engineering, Woori FISA]
tags: [RAG, Elasticsearch, Vector DB, LLM, LM Studio, Qwen, Local AI, '#우리FIS아카데미', '#우리FISA', '#AI엔지니어링', '#K-디지털트레이닝', '#우리에프아이에스', '#글로벌소프트웨어캠퍼스']
---

<br>

## 🤖 나만의 AI 비서, 직접 만들어보면 어떨까?

ChatGPT 같은 AI 서비스를 정말 편리하게 이용하고 있다. 하지만 몇몇 기밀 정보나 개인적인 데이터를 물어보기는 조금 망설여진다. 그래서 오늘은 **외부 서버 없이, 오직 내 컴퓨터 안에서 모든 것을 해결하는 나만의 RAG(검색 증강 생성) 시스템**을 만들어 보았다. **LM Studio**로 강력한 오픈소스 모델을 직접 서빙하고, **Elasticsearch**를 벡터 DB로 활용했다.

> ### 💡 "로컬 AI의 첫걸음"
> 내 데이터는 내가 지킨다! 로컬 LLM 환경을 구축하면 데이터 유출 걱정 없이, 비용 부담 없이 마음껏 AI의 능력을 활용하고 실험할 수 있다

---

### 🛠️ Step 1: Elasticsearch, 벡터 DB로 재탄생하다

첫 단계는 지금까지 열심히 배운 Elasticsearch를 똑똑한 **하이브리드 DB**로 만드는 것이다. 텍스트 검색은 물론, 의미 기반의 벡터 검색까지 가능하게🛥️

1.  **데이터 준비**: KRX에서 가져온 상장회사 정보에서 `업종`, `주요제품` 등 핵심 정보를 합쳐 **`설명`** 이라는 새로운 필드를 만들었다. **(정보의 밀도를 높이는 작업)**
2.  **벡터 필드 추가**: 인덱스 매핑에 `dense_vector` 타입을 추가했다. LM Studio로 서빙할 **Qwen3 임베딩 모델**의 벡터 차원수인 **2560**에 맞춰 `dims`를 설정하는 것이 핵심이다

```json
// 인덱스 매핑: text_embedding 필드 추가!
{
  "mappings": {
    "properties": {
      "text_embedding": { "type": "dense_vector", "dims": 2560 },
      "홈페이지" : { "type" : "keyword" }
    }
  }
}
```

--- 

### 🖥️ Step 2: LM Studio, 내 방 안의 AI 서버

LM Studio는 LLM 모델들을 아주 쉽게 다운로드하고, 내 컴퓨터에서 OpenAI처럼 API 서버로 실행시켜주는 마법 같은 도구이다. 

-   **사용한 모델**
    -   **LLM**: `Qwen/qwen3-4b-2507` (답변 생성용)
    -   **임베딩 모델**: `Qwen/Qwen3-Embedding-4B-GGUF` (텍스트 벡터화용)
-   **로컬 엔드포인트**: `http://localhost:1234/v1`

이제 `openai` 라이브러리로 `localhost`에 요청을 보내면, 내 컴퓨터의 Qwen3 모델이 응답하게 된다. 😎

```python
from openai import OpenAI

# 요청의 목적지가 내 컴퓨터의 LM Studio!
client = OpenAI(base_url="http://localhost:1234/v1", api_key="lm-studio")
```

---

### ⚙️ Step 3: RAG의 심장, 하이브리드 검색 파이프라인

이제 모든 준비는 끝났다. 사용자의 질문을 받아 최적의 정보를 찾아내고, LLM에게 전달하여 최종 답변을 생성하는 RAG 파이프라인을 조립할 차례

> #### :key: 하이브리드 검색 전략!
> "반도체 회사 알려줘" 같은 짧은 질문은 키워드 검색이, "서울에 있는 의약품 제조업 회사 중에 유망한 곳을 알려줘" 같은 긴 질문은 의미 검색이 유리하다. 질문의 길이에 따라 두 방식을 자동으로 전환하여 검색 효율을 극대화했다.

1.  **(Retrieve)** 질문이 5단어 이하면 **Lexical Search(키워드 검색)**, 그보다 길면 **Semantic Search(벡터 검색)** 로 Elasticsearch에서 관련 회사 정보를 검색합니다.
2.  **(Augment)** 검색된 회사 정보들을 예쁘게 정리해서, LLM에게 전달할 프롬프트 안에 쏙 넣어준다.
3.  **(Generate)** 정보가 보강된 프롬프트를 Qwen3 모델에게 보내, 자연스러운 최종 답변을 생성하게 한다.

🎉 이 모든 과정이 합쳐져, 사용자는 단지 질문 하나를 던졌을 뿐이지만 시스템 내부에서는 똑똑한 검색과 생성 과정이 착착 진행되는 것이죠!

---

### ✨ 오늘의 회고

오늘의 실습은 정말 **'내 것'을 만드는 기분**이 들어서 무척 뿌듯했습니다. 외부 서비스에 의존하지 않고 내 컴퓨터에서 모든 것을 통제할 수 있다는 점이 가장 매력적이었다. 특히 질문의 길이에 따라 검색 방식을 바꾸는 하이브리드 전략은 `'실제 서비스들의 검색 로직은 더욱 복잡하겠구나..'` 하는 생각이 들게 만들었다.

이제 RAG의 전체적인 흐름을 이해했으니, 다음에는 **ML(Machine Learning)** 에 대해 이론적으로 더 공부해보고 싶다. 😄 앞으로 더 다양한 모델과 기술을 조합해서 나만의 AI를 만들어 볼 생각에 가슴이 뛴다!